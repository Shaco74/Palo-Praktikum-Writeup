\documentclass{article}

\author{Kacper Cömlek}
\title{Palo Praktikum 2 - Writeup}
\date{06.05.2024}

\usepackage{multirow}
\usepackage{ulem}

\newcommand{\Aufgabe}[2]{\PSN{Aufgabe}{#1}{#2}}

\begin{document}

\maketitle
\tableofcontents 


\section{Aufgabenstellung}

  \subsection{Aufgabe 1}
  
  \begin{itemize}
  
  \item Beispielprogramm: 020\_06\_CompilerExercise
  
  \begin{itemize}
  \item In den Home Ordner kopieren
  \item Programm mit verschiedenen Compileroptionen aufrufen und \\Laufzeit notieren
  \end{itemize}

  \item Das Programm hat mehrere Durchläufe, berechne die mittlere gerundete Laufzeit
  
  \begin{itemize}
  \item Außreißer wie z.B. der erste Durchlauf werden ignoriert
  \end{itemize}

  \item Die Ergebnisse haben eine Checksum und Total, die überprüft werden müssen. 
    Wenn die Optimierung die Checksum verändert, ist das Ergebnis falsch. 
    In der Tabelle kann dann \emph{n.a. (nicht anwendbar)} eingetragen werden.

  \item Sofern nicht anders angegben verwenden wir Floating-Point Modell precise. 
    Ggf. explizit einstellen. 
  
  \item In den Einzelnen Schritten Report Dateien anlegen und versuchen anhand 
    dessen die Beobachtungen zu erklären. 
  \end{itemize}

  \subsection{Aufgabe 2} 
  Es sollen folgende Unterpunkte in eigenen Worten erklärt werden:
  \begin{itemize}
    \item Contant folding und constant propagation
    \item Loop unrolling
    \item Scheduling
    \item Algebraic reduction
  \end{itemize}
Welche Optimierung der Compiler jeweils vornimmt und welche Vorteile und ggf.
Nachteile die Optimierung haben kann. Falls angegeben beschreiben Sie bitte
auch was den Compiler ggf. daran hindern kann die jeweilige Optimierung
vorzunehmen.

\newpage

\section{Aufgabenlösung}

\subsection{Aufgabe 1 Lösung} 
Meine Lösung für Aufgabe 1 ist in Tabelle \ref{tab:aufgabe1} dargestellt\dots

\subsubsection{Aufgabe 1 - Compileroptionen}
Meine Compileroptionen \& Checksum
\begin{verbatim}
#ICC Compilation
CXX_ICC = icpc
CXXFLAGS_ICC = -fopenmp -fp-model=precise -O0
OPTFLAGS_ICC = -qopt-report=5 -qopt-report-file=$@.optrpt
LDFLAGS_ICC =  -qopenmp -qopt-report-file=ipo_test.optrpt 
               -qopt-report=5

Total = 19590.488262 Check Sum = 5001000000

#ICC Compilation für ipo
CXX_ICC = icpc
CXXFLAGS_ICC = -fopenmp -fp-model=precise -O3 -ipo
OPTFLAGS_ICC = -qopt-report=5
LDFLAGS_ICC = -qopenmp -qopt-report-file=ipo_test.optrpt 
              -qopt-report=5
\end{verbatim}

\subsubsection{Aufgabe 1 - Laufzeiten}
Es folgen die Laufzeiten für die verschiedenen Optimierungen

\begin{table}[h]
\centering
\caption{Optimization Options}
\label{tab:aufgabe1}
\begin{tabular}{|c|c|}
\hline
\textbf{Optionen} & \textbf{Mittlere Laufzeit} \\
\hline
/00 (keine Optimierung) & \sout{4,1786s} 32,635s \\ 
\hline
/02 (default Optimierung) & 4,1032s \\
\hline
/03 (aggressive Optimierung) & 4,1929s \\
\hline
% multicol
\multicolumn{2}{|c|}{\textbf{Wählen Sie für die folgenden Schritte das Setting /03}} \\
\hline
Prozessorspezifische Optimierung -xHost & 4,0935s \\
\hline
Interprozeduale Optimierung (multi-File) -ipo & 3,5788s \\
\hline
Interprozeduale + Prozessorspezifische Optimierung & 3,5753s \\
\hline
%multirow
\multirow{3}{*}{Prozessorspezifische Optimierung + } &  \\
& \\  Interprozeduale Optimierung (multi-File) & 2,4554s \\
& \\  + Floating Point Model /fast & \\
\hline
\end{tabular}
\end{table}

\subsubsection{Aufgabe 1 - Die Beobachtungen aus den Report-Dateien}
Bei der "Default-Optimierung", "Aggressive-Optimierung" und "Prozessorspezifische Optimierung" wird
weder Inlining oder Vektorisierung vom Compiler betrieben.

Bei der "Interprozeduale Optimierung (multi-File)" haben wir dann das erste mal Inlining der
Funktionen Work(double*, double*), Serier1(int), Serier2(int) und AddY(double, int)
aber auch keine Vektorisierung der Schleifen.
Bei dem fast Model haben wir hingegen Inlining und auch Vektorisierung von Serier1(int)
und Serier2(int).

Bei der "Interprozeduale + Prozessorspezifische Optimierung" kommt es darauf an ob man es mit
Multi-File-Betrachtung laufenlässt oder ohne. Bei mit Multi-File-Betrachtung verhält es sich wie bei der
"Interprozeduale Optimierung (multi-File)" und ohne die Betrachtung verhält es sich wie bei den ersten
drei beschriebenen Optimierungen.

\newpage

\subsection{Aufgabe 2 Lösung}
Moderne Compiler führen viele Veränderungen auf dem Code Durch, \\
um die Laufzeit zu verbessern. Für den Entwickler ist es äußerst nützlich \\
zu wissen, was der Compiler kann und was er nicht kann.
\subsubsection{Material}
\begin{itemize}
  \item optimizing\_cpp.pdf Kapitel 8.1
\end{itemize} 

\subsubsection{Constant Folding und Constant Propagation}
In diesem Optimierungsverfahren werden mathematische Ausdrücke in Konstanten umgewandelt. So muss das Programm nicht in jedem Durchlauf die Berechnung erneut durchführen. Sondern der Compiler macht die berechnung einmal vorher und speichert das Ergebnis. \\
\textbf{Beispiel:}

\begin{math}
int\ a = 5 * 2;
\end{math}

\begin{math}
int\ b = 2+3;
\end{math}

\begin{math}
int\ c = b / a;
\end{math}

\textbf{wird zu} 

\begin{math}
int\ a = 10;
\end{math}

\begin{math}
int\ b = 5;
\end{math}

\begin{math}
int\ c = 0.5;
\end{math}

Genau so würde auch eine Funktion ggf. in eine inline Konstante umgewandelt werden. Desweiteren wird empfohlen die Ausdrücke mit Klammern zu umschließen, um die Reihenfolge der Berechnung zu garantieren und somit die Konstantenbildung zu ermöglichen. \\
Eine Limitierung stellen jedoch komplexere Funktionen dar wie zum Beispiel die Sinusfunktion. Diese kann in der Regel nicht in eine Konstante umgewandelt werden. Manche Compiler schaffen \emph{sqrt} oder \emph{pow} Funktionen zu optimieren, jedoch ist dies nicht immer der Fall. 

\subsubsection{Loop Unrolling}
In dieser Optimierungsmethode werden Schleifen durch Inline-Code ersetzt. Dies wird insbesonders bei kleinen Schleifen durchgeführt. 
\textbf{Beispiel:}
\begin{verbatim}
for (int i = 0; i < 4; i++) {
  a[i] = b[i] + c[i];
}
\end{verbatim}
\textbf{wird zu}
\begin{verbatim}
a[0] = b[0] + c[0];
a[1] = b[1] + c[1];
a[2] = b[2] + c[2];
\end{verbatim}

Leider "unrollen" manche Compiler zu viel, dies führt dazu dass der code cache, micro-op cache und der loop buffer überlastet wird. Dies führt zu einer schlechteren Performance. Bei aggressiveren Optimierung wird eher unrolled, man muss also aufpassen ob wirklich eine Verbesserung stattfindet.

\subsubsection{Scheduling}
Der Compiler versucht die Reihenfolge der Befehle zu optimieren. Dies wird insbesonders bei Pipelining und Superskalarprozessoren wichtig. Der Compiler versucht die Befehle so anzuordnen, dass die Pipelines nicht unterbrochen werden. \\
Moderne CPUs können auch ohne die Hilfe des Compilers die Befehle umordnen, jedoch ist es für den CPU leichter, wenn der Compiler dort mithilft.

\subsubsection{Algebraic Reduction}
Die meisten Compiler können einfache mathematische Ausdrücke verinfachen wie etwa: \[
  -(-a) = a
\] 

Entwickler würden eher unwahrscheinlich solch einen Ausdruck schreiben, jedoch kann es sein dass solch ein Ausdruck infolge anderer Optimierungen entsteht wie durch zum Beispiel Inlining.

Entwickler schreiben dennoch Ausdrücke welche verinfacht werden können. Das kann aufgrund der Lesbarkeit beispielsweise passieren. Beispiel: \begin{verbatim}
if(!a && !b) => if(!(a || b)) 
\end{verbatim} 
Der Linke Ausdruck ist leichter zu lesen auch wenn er eine extra Operation braucht. 
Der Compiler optimiert das nach rechts. \\
Da es in der Algebra sehr viele Regeln für die Umformung und Vereinfachung gibt, gibt es keinen Compiler welcher alle Regeln umsetzen kann. In der Regel implementieren die Compiler unterschiedliche Regeln und sind verschieden gut im verinfachen von leichteren oder komplexeren Ausdrücken. \\
Außerdem sind die Compiler besser da drin Integer zu vereinfachen auch wenn für Floats die selben Algebra-Regeln gelten. Das hat den Hintergrund dass bei Floats leicher ungewollte Nebeneffekte auftreten können. Speziell der Verlust der Präzision ist ein Risiko.
Grundsätzlich ist es am sichersten algebraische Optimierungen händisch / manuel auszuführen.

\newpage

\section{Aufgabe 3 - Skalare Optimierung}
\textbf{Erstellen einer Baseline}
% i nee a new table with
%1 head row and a row with data, beneth that there will be a code snippet like above, insert that

\begin{table}[h]
\centering
\caption{Laufzeitmessung}
\label{tab:label}   
\begin{tabular}{|c|c|}
\hline
\textbf{Average Runtime} & \textbf{Average Performance} \\
\hline
10.5561s & 0.5085 GFLOPS/s \\ 
\hline
\end{tabular}
\end{table}

\textbf{Compilereinstellungen}
\begin{verbatim}
#ICC Copilation
CXX_ICC = icpc
CXXFLAGS_ICC = -qopenmp -fp-model=precise
OPTFLAGS_ICC = -O2 -qopt-report=5 -qopt-report-file=$@.optrpt
LDFLAGS_ICC = -qopenmp
\end{verbatim}

Wir haben uns für diese Compilereinstellungen entschieden, da wir es für sinnvoll fanden das
der Compiler nur mit der Default-Optimierung läuft. Für diese haben wir uns entschieden da
wir nicht wollten das der Compiler unseren gesamten Code von sich aus schon Optimiert und
wir wollten vermeiden das der Compiler Sachen weg Optimiert die vielleicht wichtig sind.

Bei dem Model haben wir uns für "precise" entscheiden da wir der Meinung waren das es
sinnvoll wäre, wenn der Compiler die Reihenfolge des Programmes beibehält. Wir wollten das
das Programm in der vorgegebenen Reihenfolge aus geführt wird damit wir später besser
sehen können ob unsere Optimierungen der Berechnungen etwas gebracht haben oder nicht.

\textbf{Skalare Optimierung}

\begin{table}[h]
\centering
\caption{Ergebnisse des Benchmarkings}
\label{tab:benchmarking}   
\begin{tabular}{|c|c|c|}
\hline
\textbf{Benchmark} & \textbf{Time (ns)} & \textbf{CPU Iterations} \\
\hline
BM\_New\_Process\_Ref & 64.3 & 1000000 \\ 
\hline
BM\_New\_Process\_Opt & 32.1 & 2000000 \\ 
\hline
BM\_New\_Process\_Opt & 16.5 & 3000000 \\ 
\hline
BM\_New\_Process\_Opt & 3.11 & 224955341 \\ 
\hline
\end{tabular}
\end{table}

\begin{table}[h]
\centering
\caption{Laufzeitmessung}
\label{tab:laufzeitmessung}   
\begin{tabular}{|c|c|}
\hline
\textbf{Average Runtime} & \textbf{Average Performance} \\
\hline
2.9314 Seconds & 1.8313 GFLOPS/s \\ 
\hline
\end{tabular}
\end{table}

\newpage



\textbf{Die Änderungen am Quellcode}

Vorher: 
\begin{verbatim}
for (int j = 0; j < nr_Particles; j++) {
const float dx = partikel[j].x - partikel[i].x;
const float dy = partikel[j].y - partikel[i].y;
const float dz = partikel[j].z - partikel[i].z;
...
}
\end{verbatim}

Nachher
\begin{verbatim}
Particle partikelI = partikel[i];
…
for (int j = 0; j < nr_Particles; j++) {
const float dx = partikel[j].x - partikelI.x;
const float dy = partikel[j].y - partikelI.y;
const float dz = partikel[j].z - partikelI.z;
…
}
\end{verbatim}

Vorher
\begin{verbatim}
const float drPower32 = pow(drSquared, 3.0 / 2.0);
\end{verbatim}

Nachher
\begin{verbatim}
const float drPower32 = drSquared * sqrt(drSquared);
\end{verbatim}

Vorher
\begin{verbatim}
Fx += dx / drPower32;
Fy += dy / drPower32;
Fz += dz / drPower32;
\end{verbatim}

Nachher
\begin{verbatim}
Fx += dx * invDrPower32;
Fy += dy * invDrPower32;
Fz += dz * invDrPower32;
\end{verbatim}

\end{document}
